{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photo to Sketch: Your Artificial Street Artist in the Cloud\n",
    "\n",
    "**Photo to Sketch: Your Artificial Street Artist in the Cloud**, showcase an ML use case that take pictures in an ios application and generate their sketched version. To accomplish it, hosts a pre-trained Fast Arbitrary image style transfer model from TensorFlow Hub in Amazon SageMaker. For details on the ML model,you can check the following website: https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\n",
    "\n",
    "The goal of this Jupyter Notebook, is to host the pre-trained model in an Amazon SageMaker Endpoint and check if inference works with a sample image. This Notebook can be executed using the *conda_python3* Kernel in an Amazon SageMaker Notebook instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Amazon SageMaker Execution Role\n",
    "\n",
    "Before running the notebook, check that your Amazon SageMaker IAM role have the necessary permissions.\n",
    "\n",
    "- arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryFullAccess\n",
    "- arn:aws:iam::aws:policy/AmazonS3FullAccess\n",
    "- arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\n",
    "- arn:aws:iam::aws:policy/AmazonSageMakerPipelinesIntegrations\n",
    "- arn:aws:iam::aws:policy/AWSLambda_FullAccess\n",
    "- arn:aws:iam::aws:policy/AWSCodePipeline_FullAccess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import libraries and install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import datetime\n",
    "import base64\n",
    "from sagemaker import get_execution_role\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import json\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.session\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "\n",
    "#Import Amazon SageMaker pipelines\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.model_metrics import (\n",
    "    MetricsSource,\n",
    "    ModelMetrics,\n",
    ")\n",
    "from sagemaker.processing import (\n",
    "    ProcessingInput,\n",
    "    ProcessingOutput,\n",
    "    ScriptProcessor,\n",
    ")\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    ")\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import (\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    ")\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.workflow.lambda_step import (LambdaStep,LambdaOutput,LambdaOutputTypeEnum,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import create_lambda_role function from lambda/iam_helper.py\n",
    "import sys\n",
    "sys.path.insert(0, \"./lambda\")\n",
    "import iam_helper\n",
    "from iam_helper import create_lambda_role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Variables\n",
    "\n",
    "Define the necessary parameters to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Session variables\n",
    "role = get_execution_role()\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "region = boto3.Session().region_name\n",
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "print(account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3 bucket\n",
    "bucket = \"photo-to-sketch-{}\".format(account_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repository name for the custom image for the endpoint.  \n",
    "image_repo_name = \"photo-to-sketch-byoc-tensorflow\"\n",
    "ts = datetime.datetime.now().strftime('%m%d-%H%M')\n",
    "endpoint_name = \"style-transfer-{}\".format(ts)\n",
    "image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account_id, region, image_repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amazon S3 model path\n",
    "model_url = f\"s3://{bucket}/model/magenta_arbitrary-image-stylization-v1-256_2.tar.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Host Pre-trained ML model to Amazon SageMaker Endpoint for real-time inference\n",
    "\n",
    "To host the pre-trained Tensorflow model specified above, we will be creating our custom container for inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Create ECR repository to store the custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ecr = boto3.client('ecr')\n",
    "    image_repo = ecr.create_repository(repositoryName = image_repo_name)   \n",
    "except Exception as e:\n",
    "    print(\"Error: {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Locally build the docker image and push it to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-studio-image-build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "chmod +x src/serve\n",
    "\n",
    "sm-docker build . --repository photo-to-sketch-byoc-tensorflow:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3 Create Amazon SageMaker Model & Endpoint via Amazon SageMaker Pipelines\n",
    "\n",
    "To deploy the ML model into an Amazon SageMaker endpoint, we will create a deployment pipeline by leveraging Amazon SageMaker Pipelines. Find below the different steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name=\"style-transfer-pipeline-tf\"\n",
    "base_job_prefix=\"style-transfer-tf-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Amazon SageMaker model step\n",
    "\n",
    "The first step in our pipeline will create the Amazon SageMaker model. It will be executed in a custom Lambda step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./lambda/create_model.py\n",
    "\n",
    "\"\"\"\n",
    "    This Lambda function creates a SageMaker model.\n",
    "    As input event, it receives the endpoint_name, the image_uri and the execution role. \n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import boto3 \n",
    "     \n",
    "def lambda_handler(event, context):   \n",
    "    \n",
    "    #Amazon SageMaker session\n",
    "    sm = boto3.client(\"sagemaker\")\n",
    "    region = boto3.Session().region_name\n",
    "    \n",
    "    #Input parameters\n",
    "    endpoint_name = event['endpoint_name']\n",
    "    image_uri = event['image_uri']\n",
    "    role = event['role']\n",
    "    model_url = event['model_path']\n",
    "    \n",
    "    #Create a Model using Amazon SageMaker \n",
    "    model = sm.create_model(\n",
    "        ModelName=endpoint_name,\n",
    "            Containers=[\n",
    "                {\n",
    "                    \"Image\": image_uri,\n",
    "                    'Mode': 'SingleModel',\n",
    "                    'ModelDataUrl': model_url,\n",
    "                },\n",
    "            ],\n",
    "            ExecutionRoleArn=role,\n",
    "            EnableNetworkIsolation=False,\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Created Model!\"),\n",
    "        \"model_name\": str(endpoint_name),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create AWS Lambda role for custom step\n",
    "lambda_role = create_lambda_role(\"lambda-deployment-role\")\n",
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
    "function_name = \"sagemaker-lambda-step-sagemaker-model-\" + current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lambda function\n",
    "func = Lambda(\n",
    "    function_name=function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"./lambda/create_model.py\",\n",
    "    handler=\"create_model.lambda_handler\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output parameters for Lambda\n",
    "output_param_1 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_3 = LambdaOutput(output_name=\"model_name\", output_type=LambdaOutputTypeEnum.String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = f'{account_id}.dkr.ecr.{region}.amazonaws.com/{image_repo_name}:latest'\n",
    "\n",
    "step_create_model_lambda = LambdaStep(\n",
    "    name=\"LambdaStepModelCreate\",\n",
    "    lambda_func=func,\n",
    "    inputs={\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"image_uri\": image_uri,\n",
    "        \"role\": lambda_role,\n",
    "        \"model_path\": model_url\n",
    "    },\n",
    "    outputs=[output_param_1, output_param_2, output_param_3],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Amazon SageMaker Endpoint & Endpoint config step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./lambda/create_endpoint.py\n",
    "\n",
    "\"\"\"\n",
    "    This Lambda function creates an Endpoint Configuration and deploys a model to an Endpoint. \n",
    "    The name of the model to deploy is provided via the event argument.\n",
    "    The Lambda also saves the endpoint_name in Parameter Store.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import boto3 \n",
    "import time\n",
    "    \n",
    "def lambda_handler(event, context):    \n",
    "    \n",
    "    #Amazon SageMaker session\n",
    "    sm = boto3.client(\"sagemaker\")\n",
    "    region = boto3.Session().region_name\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "    \n",
    "    time.sleep(10)\n",
    "    \n",
    "    #Create Endpoint Configuration & endpoint in a Lambda\n",
    "    endpoint_config = sm.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                'VariantName': endpoint_name,\n",
    "                'ModelName': endpoint_name,\n",
    "                'InitialInstanceCount': 1,\n",
    "                'InstanceType': 'ml.m4.xlarge',\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    #Create Endpoint\n",
    "    endpoint = sm.create_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        EndpointConfigName=endpoint_name\n",
    "    )\n",
    "    \n",
    "    #Register endpoint name to Parameter Store\n",
    "    ssm = boto3.client('ssm')\n",
    "    ssm.put_parameter(Name='endpoint_name',Value=endpoint_name,Type='String',Overwrite=True)\n",
    "    \n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": json.dumps(\"Created Endpoint!\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create AWS Lambda role for custom step\n",
    "lambda_role = create_lambda_role(\"lambda-deployment-role\")\n",
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
    "function_name = \"sagemaker-lambda-endpoint-step-sagemaker-model-\" + current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lambda function\n",
    "func = Lambda(\n",
    "    function_name=function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"./lambda/create_endpoint.py\",\n",
    "    handler=\"create_endpoint.lambda_handler\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output parameters for Lambda\n",
    "output_param_4 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_5 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_create_endpoint_lambda = LambdaStep(\n",
    "    name=\"LambdaStepEndpointCreate\",\n",
    "    lambda_func=func,\n",
    "    inputs={\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "    },\n",
    "    outputs=[output_param_4, output_param_5],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Amazon SageMaker pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "sagemaker_session = sagemaker.session.Session(boto_session=boto_session, sagemaker_client=sm_client)\n",
    "\n",
    "# pipeline instance\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[],\n",
    "    steps=[step_create_model_lambda,step_create_endpoint_lambda],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Execute the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition = json.loads(pipeline.definition())\n",
    "print(definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn = role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_role = create_lambda_role(\"lambda-deployment-role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wait until endpoint is provisioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.describe_endpoint(EndpointName = endpoint_name)\n",
    "print(\"Endpoint {} status: {}\".format(endpoint_name,response['EndpointStatus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while response['EndpointStatus'] == 'Creating':\n",
    "    response = sm.describe_endpoint(EndpointName = endpoint_name)\n",
    "    time.sleep(10)\n",
    "    print(\"Endpoint creating...\")\n",
    "print(\"Endpoint created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Inference \n",
    "\n",
    "Now that we have the Amazon SageMaker Endpoint provisioned with our ML pre-trained model, we are ready to test inference in our model!\n",
    "To do so, we will leverage the AWS Lambda previously deployed by our CFN template!\n",
    "\n",
    "Our AWS Lambda is a container-based image, so we will build the image and push it there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.0 Create ECR repository for hosting Lambda image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_repo_name = \"photo-to-sketch-lambda-tensorflow\"\n",
    "try:\n",
    "    ecr = boto3.client('ecr')\n",
    "    image_repo = ecr.create_repository(repositoryName = image_repo_name)   \n",
    "except Exception as e:\n",
    "    print(\"Error: {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Create Lambda image and push it to ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd lambda-inference\n",
    "\n",
    "sm-docker build --repository photo-to-sketch-lambda-tensorflow:latest . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Create Lambda with our new deployed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_func_name = f\"photo-to-sketch-inference-lambda-{account_id}\"\n",
    "latest_image = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/photo-to-sketch-lambda-tensorflow:latest\"\n",
    "print(latest_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create container-based Lambda function\n",
    "!aws lambda create-function --region $region --function-name $lambda_func_name \\\n",
    "    --package-type Image  \\\n",
    "    --code ImageUri=$latest_image   \\\n",
    "    --role $lambda_role \\\n",
    "    --memory-size 1000 \\\n",
    "    --timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latest image pushed in the ECR repository\n",
    "print(f\"My latest image for Lambda pushed to ECR: {latest_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case you would like to update Lambda's image:\n",
    "#!aws lambda update-function-code --function-name $lambda_func_name --image-uri $latest_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3 Test inference with a sample image!\n",
    "\n",
    "**Note: Wait until Lambda has been updated. You can check it in the AWS Console**\n",
    "\n",
    "Now, to be able to test how our model performs, we provided one sample image from a dog. You can find the original image under /img folder.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode image as base64\n",
    "\n",
    "Our ML model expects the image as a base64 encoded image. Therefore, we will visualize the original image and encode it as base64. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open image using PIL\n",
    "from PIL import Image\n",
    "im = Image.open(\"./img/dog.jpeg\")\n",
    "rgb_im = im.convert('RGB')\n",
    "rgb_im.save(\"./img/dog.jpeg\")\n",
    "#Encode the image as base64\n",
    "encoded = base64.b64encode(open(\"./img/dog.jpeg\", \"rb\").read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the original sample image\n",
    "display(rgb_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decide effectStyle\n",
    "\n",
    "We have 4 different styles that you can select from different painters, select the style you want the most! Find below the styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "print(\"Style 1: \\n\")\n",
    "Image('./img/style/1.jpeg', width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Style 2: \\n\")\n",
    "Image('./img/style/2.jpeg', width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Style 3: \\n\")\n",
    "Image('./img/style/3.jpeg', width=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Style 4: \\n\")\n",
    "Image('./img/style/4.jpeg', width=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Invoke Lambda with the selected effectStyle\n",
    "\n",
    "Invoke the AWS Lambda function 4 times and get the styled dog image with the 4 different styles!\n",
    "\n",
    "Our AWS Lambda will be later called by API Gateway, therefore, the payload should have the same format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "encoded_images = []\n",
    "for effect_style in [1,2,3,4]:\n",
    "    #Lambda event - encoded image and effect style selected\n",
    "    payload =  json.dumps({'body':{'image' : str(encoded), 'effectType' : str(effect_style)}}).encode(\"utf-8\")\n",
    "    #Invoke Lambda\n",
    "    client = boto3.client('lambda')\n",
    "    response = client.invoke(FunctionName=lambda_func_name,InvocationType='RequestResponse',Payload=payload)\n",
    "    #print(json.loads(response['Payload'].read().decode()))\n",
    "    payload = json.loads(response['Payload'].read().decode())['body']\n",
    "    style_image_encoded = json.loads(payload)['image']\n",
    "    #Save base64 encoded image\n",
    "    encoded_images.append(style_image_encoded)\n",
    "    #Decode from base64 to PIL image\n",
    "    image = base64.b64decode(str(style_image_encoded))\n",
    "    img = Image.open(io.BytesIO(image))\n",
    "    img.save(\"./img/dog-styled-{}.jpeg\".format(effect_style), 'jpeg')\n",
    "    print(\"Image styled {} saved!\".format(effect_style))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display the styled images\n",
    "\n",
    "See below your dog image styled with the 4 different paintings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Style 1: \\n\")\n",
    "image = base64.b64decode(str(encoded_images[0]))       \n",
    "img = Image.open(io.BytesIO(image))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Style 2: \\n\")\n",
    "image = base64.b64decode(str(encoded_images[1]))       \n",
    "img = Image.open(io.BytesIO(image))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Style 3: \\n\")\n",
    "image = base64.b64decode(str(encoded_images[2]))       \n",
    "img = Image.open(io.BytesIO(image))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Style 4: \\n\")\n",
    "image = base64.b64decode(str(encoded_images[3]))       \n",
    "img = Image.open(io.BytesIO(image))\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Delete endpoint\n",
    "\n",
    "Delete the Amazon SageMaker endpoint when you are done with inference the model! :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sm.delete_endpoint(EndpointName = endpoint_name))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
